{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d59230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bcp6w\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, PreTrainedTokenizerFast, TFAutoModelForMaskedLM, TFAutoModelForTokenClassification, TFMT5ForConditionalGeneration\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as kl\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3261a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def destringify(string):\n",
    "    numlist = tf.strings.split(string)\n",
    "    numlist = tf.strings.to_number(numlist, out_type=tf.dtypes.int32)\n",
    "    return numlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4fa08f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(numlist):\n",
    "    string = ''\n",
    "    for num in numlist:\n",
    "        string = string + str(num)+' '\n",
    "        string1 = string.rstrip()\n",
    "    return string1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80e8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_maskify(string):\n",
    "    numlist = tf.strings.split(string)\n",
    "    numlist = tf.strings.to_number(numlist, out_type=tf.dtypes.int32)\n",
    "    masklist = tf.math.not_equal(numlist, tf.constant([1]))\n",
    "    return tf.cast(masklist, tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557804a",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d923931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFXLMRobertaForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFXLMRobertaForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = transformers.TFXLMRobertaForTokenClassification.from_pretrained('xlm-roberta-base', num_labels=1, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7fb0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfxlm_roberta_for_token_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFRobertaMainLayer  multiple                 277453056 \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277,453,825\n",
      "Trainable params: 277,453,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1840d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x21f6480cf10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.load_weights('XLM-Roberta_take_3_WEIGHTS_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18841f",
   "metadata": {},
   "source": [
    "# Predict WMT data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61b67a",
   "metadata": {},
   "source": [
    "### Build WMT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a921fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(string):\n",
    "    x = string.split()\n",
    "    out = [y=='BAD' for y in x]\n",
    "    \n",
    "    return np.asarray(out).astype(int)\n",
    "\n",
    "def get_zh_word_labels(string):\n",
    "    x = string.split()\n",
    "    out = [y=='BAD' for y in x]\n",
    "    word = [out[i] for i in range(len(out)) if i%2==1]\n",
    "    \n",
    "    return np.asarray(word).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440ff4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_labels(labels, tokens):\n",
    "    ## converts WMT's word-labels into token-labels\n",
    "    new_labels = np.zeros_like(tokens['input_ids'])\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        word_ids = tokens.word_ids(i)\n",
    "        cur_labels = labels[i]\n",
    "        for j in range(len(word_ids)):\n",
    "            if word_ids[j] != None:\n",
    "                new_labels[i,j]= cur_labels[word_ids[j]]\n",
    "    \n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32d50bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bcp6w\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-train/train.src', sep=\"/n\", header=None, names=[\"Source\"])\n",
    "train_df['Target'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-train/train.mt', sep=\"/n\", header=None)\n",
    "train_df['Post Edits'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-train/train.pe', sep=\"/n\", header=None)\n",
    "train_df['Source Tags'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-train/train.source_tags', sep=\"/n\", header=None)\n",
    "train_df[\"Target Tags\"] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-train/train.tags', sep=\"/n\", header=None)\n",
    "\n",
    "dev_df = df = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-dev/dev.src', sep=\"/n\", header=None, names=[\"Source\"])\n",
    "dev_df['Target'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-dev/dev.mt', sep=\"/n\", header=None)\n",
    "dev_df['Post Edits'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-dev/dev.pe', sep=\"/n\", header=None)\n",
    "dev_df['Source Tags'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-dev/dev.source_tags', sep=\"/n\", header=None)\n",
    "dev_df[\"Target Tags\"] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-dev/dev.tags', sep=\"/n\", header=None)\n",
    "\n",
    "multi_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "train_input = [train_df['Source'][i] + multi_tokenizer.sep_token + train_df['Target'][i] for i in range(len(train_df['Source']))]\n",
    "dev_input = [dev_df['Source'][i] + multi_tokenizer.sep_token + dev_df['Target'][i] for i in range(len(dev_df['Source']))]\n",
    "\n",
    "train_en_labels = train_df[\"Source Tags\"].map(get_labels)\n",
    "train_zh_labels = train_df[\"Target Tags\"].map(get_zh_word_labels)\n",
    "\n",
    "dev_en_labels = dev_df[\"Source Tags\"].map(get_labels)\n",
    "dev_zh_labels = dev_df[\"Target Tags\"].map(get_zh_word_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb6963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_split = train_df[\"Source\"].map(lambda x: x.split())\n",
    "train_zh_split = train_df[\"Target\"].map(lambda x: x.split())\n",
    "\n",
    "dev_en_split = dev_df[\"Source\"].map(lambda x: x.split())\n",
    "dev_zh_split = dev_df[\"Target\"].map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a8bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_df.shape[0]):\n",
    "    assert len(train_en_split[i]) == len(train_en_labels[i])\n",
    "    assert len(train_zh_split[i]) == len(train_zh_labels[i]), print(i)\n",
    "    \n",
    "for i in range(dev_df.shape[0]):\n",
    "    assert len(dev_en_split[i]) == len(dev_en_labels[i])\n",
    "    assert len(dev_zh_split[i]) == len(dev_zh_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764a43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = [train_en_split[i] + [multi_tokenizer.eos_token] + train_zh_split[i] for i in range(len(train_en_split))]\n",
    "dev_input = [dev_en_split[i] + [multi_tokenizer.eos_token] + dev_zh_split[i] for i in range(len(dev_en_split))]\n",
    "\n",
    "train_toks = multi_tokenizer(train_input, max_length=256, padding='max_length', truncation=True, is_split_into_words=True, return_tensors='tf')\n",
    "dev_toks = multi_tokenizer(dev_input, max_length=256, padding='max_length', truncation=True, is_split_into_words=True,  return_tensors='tf')\n",
    "\n",
    "train_labels = [list(train_en_labels[i]) + [0] + list(train_zh_labels[i]) for i in range(len(train_en_labels))]\n",
    "dev_labels = [list(dev_en_labels[i]) + [0] + list(dev_zh_labels[i]) for i in range(len(dev_en_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f36b044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expanded_labels = expand_labels(train_labels, train_toks)\n",
    "dev_expanded_labels = expand_labels(dev_labels, dev_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6783cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_train_ids = tf.data.Dataset.from_tensor_slices(train_toks['input_ids'])\n",
    "wmt_train_attention = tf.data.Dataset.from_tensor_slices(train_toks['attention_mask'])\n",
    "wmt_train_labels = tf.data.Dataset.from_tensor_slices(train_expanded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062b99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_train_ds = tf.data.Dataset.zip((wmt_train_ids, wmt_train_attention))\n",
    "wmt_train_ds = tf.data.Dataset.zip((wmt_train_ds, wmt_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc77a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_dev_ids = tf.data.Dataset.from_tensor_slices(dev_toks['input_ids'])\n",
    "wmt_dev_attention = tf.data.Dataset.from_tensor_slices(dev_toks['attention_mask'])\n",
    "wmt_dev_labels = tf.data.Dataset.from_tensor_slices(dev_expanded_labels)\n",
    "\n",
    "wmt_dev_ds = tf.data.Dataset.zip((wmt_dev_ids, wmt_dev_attention))\n",
    "wmt_dev_ds = tf.data.Dataset.zip((wmt_dev_ds, wmt_dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "869cc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_train_ds = wmt_train_ds.batch(12)\n",
    "wmt_dev_ds = wmt_dev_ds.batch(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d71c54",
   "metadata": {},
   "source": [
    "### Import Test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b05ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_df = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-test20/test20.src', sep=\"/n\", header=None, names=[\"Source\"])\n",
    "test20_df['Target'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-test20/test20.mt', sep=\"/n\", header=None)\n",
    "test20_df['Post Edits'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-test20/test20.pe', sep=\"/n\", header=None)\n",
    "test20_df['Source Tags'] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-test20/test20.source_tags', sep=\"/n\", header=None)\n",
    "test20_df[\"Target Tags\"] = pd.read_csv('./WMT2021 Data/Extracted_WMT2021_data/en-zh-test20/test20.tags', sep=\"/n\", header=None)\n",
    "\n",
    "multi_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "test20_input = [test20_df['Source'][i] + multi_tokenizer.sep_token + test20_df['Target'][i] for i in range(len(test20_df['Source']))]\n",
    "\n",
    "test20_en_labels = test20_df[\"Source Tags\"].map(get_labels)\n",
    "test20_zh_labels = test20_df[\"Target Tags\"].map(get_zh_word_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0044c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_en_split = test20_df[\"Source\"].map(lambda x: x.split())\n",
    "test20_zh_split = test20_df[\"Target\"].map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e249551",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test20_df.shape[0]):\n",
    "    assert len(test20_en_split[i]) == len(test20_en_labels[i])\n",
    "    assert len(test20_zh_split[i]) == len(test20_zh_labels[i]), print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01135318",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_input = [test20_en_split[i] + [multi_tokenizer.eos_token] + test20_zh_split[i] for i in range(len(test20_en_split))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "278411b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_toks = multi_tokenizer(test20_input, max_length=256, padding='max_length', truncation=True, is_split_into_words=True, return_tensors='tf')\n",
    "\n",
    "test20_labels = [list(test20_en_labels[i]) + [0] + list(test20_zh_labels[i]) for i in range(len(test20_en_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94c962c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_expanded_labels = expand_labels(test20_labels, test20_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb1c4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_test20_ids = tf.data.Dataset.from_tensor_slices(test20_toks['input_ids'])\n",
    "wmt_test20_attention = tf.data.Dataset.from_tensor_slices(test20_toks['attention_mask'])\n",
    "wmt_test20_labels = tf.data.Dataset.from_tensor_slices(test20_expanded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99828b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_test20_ds = tf.data.Dataset.zip((wmt_test20_ids, wmt_test20_attention))\n",
    "wmt_test20_ds = tf.data.Dataset.zip((wmt_test20_ds, wmt_test20_labels))\n",
    "\n",
    "wmt_test20_ds = wmt_test20_ds.batch(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e622a",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1da439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = base_model.predict(wmt_train_ds)\n",
    "dev_preds = base_model.predict(wmt_dev_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6dd03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_preds = base_model.predict(wmt_test20_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acb3e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83311844],\n",
       "       [ 0.1735177 ],\n",
       "       [ 0.2638688 ],\n",
       "       [ 0.2962104 ],\n",
       "       [ 0.4133141 ],\n",
       "       [ 0.06487624],\n",
       "       [ 0.21404845],\n",
       "       [ 0.07419204],\n",
       "       [ 0.0586598 ],\n",
       "       [ 0.24233077],\n",
       "       [ 0.28665268],\n",
       "       [ 0.1416643 ],\n",
       "       [ 0.12636887],\n",
       "       [ 0.02781042],\n",
       "       [ 0.10851131],\n",
       "       [ 0.1414358 ],\n",
       "       [ 0.9385923 ],\n",
       "       [ 0.9500521 ],\n",
       "       [-0.9694003 ],\n",
       "       [ 0.06399247],\n",
       "       [ 0.05730013],\n",
       "       [ 0.06293802],\n",
       "       [ 0.06669658],\n",
       "       [ 0.06876331],\n",
       "       [ 0.09375519],\n",
       "       [ 0.08492374],\n",
       "       [ 0.06584972],\n",
       "       [ 0.0966587 ],\n",
       "       [ 0.08480928],\n",
       "       [ 0.06998149],\n",
       "       [ 0.07517445],\n",
       "       [ 0.08481773],\n",
       "       [ 0.15928108],\n",
       "       [ 0.37591457],\n",
       "       [ 0.28743386],\n",
       "       [ 0.10822016],\n",
       "       [ 0.1453422 ],\n",
       "       [ 0.10779797],\n",
       "       [ 0.10894126],\n",
       "       [ 0.25936478],\n",
       "       [ 0.2758379 ],\n",
       "       [ 0.06275497],\n",
       "       [ 0.0800153 ],\n",
       "       [ 0.07172898],\n",
       "       [ 0.1218376 ],\n",
       "       [ 0.16971388],\n",
       "       [ 0.20480767],\n",
       "       [ 0.3012805 ],\n",
       "       [ 0.92991924],\n",
       "       [ 0.93899125],\n",
       "       [-0.9691204 ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ],\n",
       "       [-0.968989  ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds.logits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3126d",
   "metadata": {},
   "source": [
    "## Process Predictions into Masked Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29369544",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_input = [train_en_split[i] for i in range(len(train_en_split))]\n",
    "dev_en_input = [dev_en_split[i] for i in range(len(dev_en_split))]\n",
    "train_en_tokens = multi_tokenizer(train_en_input, is_split_into_words=True)\n",
    "dev_en_tokens = multi_tokenizer(dev_en_input, is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45e81c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_en_input = [test20_en_split[i] for i in range(len(test20_en_split))]\n",
    "test20_en_tokens = multi_tokenizer(test20_en_input, is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb72a628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<mask>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14ab5ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 250001, 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_tokenizer.encode('<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49db5dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 581,\n",
       " 4568,\n",
       " 64718,\n",
       " 1846,\n",
       " 7068,\n",
       " 51894,\n",
       " 7,\n",
       " 98,\n",
       " 678,\n",
       " 1919,\n",
       " 91,\n",
       " 47416,\n",
       " 79442,\n",
       " 19,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en_tokens['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e2cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in train_en_tokens['input_ids']:\n",
    "    tok.append(2)\n",
    "for tok in dev_en_tokens['input_ids']:\n",
    "    tok.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b630a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in test20_en_tokens['input_ids']:\n",
    "    tok.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e53a1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logits = train_preds.logits\n",
    "dev_logits = dev_preds.logits\n",
    "\n",
    "train_mask = np.greater(train_logits, [0.5])\n",
    "dev_mask = np.greater(dev_logits, [0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d35d9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.squeeze(train_mask)\n",
    "dev_mask = np.squeeze(dev_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "075fdbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_logits = test20_preds.logits\n",
    "test20_mask = np.greater(test20_logits, [0.5])\n",
    "test20_mask = np.squeeze(test20_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7294c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_60_mask = np.squeeze(np.greater(train_logits, [0.6]))\n",
    "dev_60_mask = np.squeeze(np.greater(dev_logits, [0.6]))\n",
    "test20_60_mask = np.squeeze(np.greater(test20_logits, [0.6]))\n",
    "\n",
    "train_75_mask = np.squeeze(np.greater(train_logits, [0.75]))\n",
    "dev_75_mask = np.squeeze(np.greater(dev_logits, [0.75]))\n",
    "test20_75_mask = np.squeeze(np.greater(test20_logits, [0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bd8984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_40_mask = np.squeeze(np.greater(train_logits, [0.4]))\n",
    "dev_40_mask = np.squeeze(np.greater(dev_logits, [0.4]))\n",
    "test20_40_mask = np.squeeze(np.greater(test20_logits, [0.4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4f4d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_mask)):\n",
    "    for j in range(len(train_en_tokens[i])):\n",
    "        train_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(dev_mask)):\n",
    "    for j in range(len(dev_en_tokens[i])):\n",
    "        dev_mask[i][j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "168d281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_indices = np.nonzero(train_mask)\n",
    "mask_dev_indices = np.nonzero(dev_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e8a9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = train_toks['input_ids'].numpy()\n",
    "dev_tokens = dev_toks['input_ids'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "544e3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = np.where(train_mask, 250001, train_tokens)\n",
    "masked_dev = np.where(dev_mask, 250001, dev_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc2536e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test20_mask)):\n",
    "    for j in range(len(test20_en_tokens[i])):\n",
    "        test20_mask[i][j] = False\n",
    "\n",
    "mask_test20_indices = np.nonzero(test20_mask)\n",
    "\n",
    "test20_tokens = test20_toks['input_ids'].numpy()\n",
    "\n",
    "masked_test20 = np.where(test20_mask, 250001, test20_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a64413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_60_mask)):\n",
    "    for j in range(len(train_en_tokens[i])):\n",
    "        train_60_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(dev_60_mask)):\n",
    "    for j in range(len(dev_en_tokens[i])):\n",
    "        dev_60_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(test20_60_mask)):\n",
    "    for j in range(len(test20_en_tokens[i])):\n",
    "        test20_60_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(train_75_mask)):\n",
    "    for j in range(len(train_en_tokens[i])):\n",
    "        train_75_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(dev_75_mask)):\n",
    "    for j in range(len(dev_en_tokens[i])):\n",
    "        dev_75_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(test20_75_mask)):\n",
    "    for j in range(len(test20_en_tokens[i])):\n",
    "        test20_75_mask[i][j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4313d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_40_mask)):\n",
    "    for j in range(len(train_en_tokens[i])):\n",
    "        train_40_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(dev_40_mask)):\n",
    "    for j in range(len(dev_en_tokens[i])):\n",
    "        dev_40_mask[i][j] = False\n",
    "        \n",
    "for i in range(len(test20_40_mask)):\n",
    "    for j in range(len(test20_en_tokens[i])):\n",
    "        test20_40_mask[i][j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_indices_60 = np.nonzero(train_60_mask)\n",
    "mask_dev_indices_60 = np.nonzero(dev_60_mask)\n",
    "mask_test20_indices_60 = np.nonzero(test20_60_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "997cb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = train_toks['input_ids'].numpy()\n",
    "dev_tokens = dev_toks['input_ids'].numpy()\n",
    "test20_tokens = test20_toks['input_ids'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "819c25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_60_train = np.where(train_60_mask, 250001, train_tokens)\n",
    "masked_60_dev = np.where(dev_60_mask, 250001, dev_tokens)\n",
    "masked_60_test20 = np.where(test20_60_mask, 250001, test20_tokens)\n",
    "\n",
    "masked_75_train = np.where(train_75_mask, 250001, train_tokens)\n",
    "masked_75_dev = np.where(dev_75_mask, 250001, dev_tokens)\n",
    "masked_75_test20 = np.where(test20_75_mask, 250001, test20_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aca61fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_40_train = np.where(train_40_mask, 250001, train_tokens)\n",
    "masked_40_dev = np.where(dev_40_mask, 250001, dev_tokens)\n",
    "masked_40_test20 = np.where(test20_40_mask, 250001, test20_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d41f18b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,   2161,   1702,  14487,   1210,      6,      4,  12439,\n",
       "         2069,  34377,    297,   1919,   3525,  28560,     44,  41945,\n",
       "          214,    111,   1215,     44,      6,      4, 241599, 108171,\n",
       "            7,   1295,   5655,   3041,   2945,      6,      4,   1829,\n",
       "        50094,    953,    111,   1919,  17428,    966,  16398,    294,\n",
       "        99653,      6,      5,      2,   1210,      6,    470,    427,\n",
       "            6,    630,   1702,      6,    635,      6,      4,      6,\n",
       "        80884,      6,   6347,   3942,      6,   4511,  47437,      6,\n",
       "           43,  17428,    966,  16398,    294, 250001, 250001, 250001,\n",
       "        23830,    953,      6,   5525,      6,      4,      6,  18325,\n",
       "            6,    274,  47437,      6,     43,  59515,      6, 250001,\n",
       "           44,  13129,      6,     43, 250001, 250001, 250001,      6,\n",
       "            4,      6,   6628,      6,    465,      6,  17206, 210893,\n",
       "         3300,   1275,      6,  19506,      6,     43,      6,  11480,\n",
       "         7770,      6,     30,      2,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1,\n",
       "            1,      1,      1,      1,      1,      1,      1,      1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_60_dev[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4523ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_list = []\n",
    "dev_mask_list = []\n",
    "\n",
    "for seq in masked_train:\n",
    "    string = stringify(seq)\n",
    "    train_mask_list.append(string)\n",
    "    \n",
    "for seq in masked_dev:\n",
    "    string = stringify(seq)\n",
    "    dev_mask_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86783cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20_mask_list = []\n",
    "\n",
    "for seq in masked_test20:\n",
    "    string = stringify(seq)\n",
    "    test20_mask_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a41e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_60_list = []\n",
    "dev_mask_60_list = []\n",
    "test20_mask_60_list = []\n",
    "\n",
    "for seq in masked_60_train:\n",
    "    string = stringify(seq)\n",
    "    train_mask_60_list.append(string)\n",
    "    \n",
    "for seq in masked_60_dev:\n",
    "    string = stringify(seq)\n",
    "    dev_mask_60_list.append(string)\n",
    "    \n",
    "for seq in masked_60_test20:\n",
    "    string = stringify(seq)\n",
    "    test20_mask_60_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51601685",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_75_list = []\n",
    "dev_mask_75_list = []\n",
    "test20_mask_75_list = []\n",
    "\n",
    "for seq in masked_75_train:\n",
    "    string = stringify(seq)\n",
    "    train_mask_75_list.append(string)\n",
    "    \n",
    "for seq in masked_75_dev:\n",
    "    string = stringify(seq)\n",
    "    dev_mask_75_list.append(string)\n",
    "    \n",
    "for seq in masked_75_test20:\n",
    "    string = stringify(seq)\n",
    "    test20_mask_75_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44ce0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_40_list = []\n",
    "dev_mask_40_list = []\n",
    "test20_mask_40_list = []\n",
    "\n",
    "for seq in masked_40_train:\n",
    "    string = stringify(seq)\n",
    "    train_mask_40_list.append(string)\n",
    "    \n",
    "for seq in masked_40_dev:\n",
    "    string = stringify(seq)\n",
    "    dev_mask_40_list.append(string)\n",
    "    \n",
    "for seq in masked_40_test20:\n",
    "    string = stringify(seq)\n",
    "    test20_mask_40_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "048deada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 31384 6032 14432 6 4 107154 118066 17368 136247 102 23 10862 111 13625 39 1681 6 5 2 6 3074 6 274 6 170772 250001 250001 6 217398 6 43793 6 274 6 2229 6 62029 43024 6 1589 6 7499 6 3987 2008 26027 6 15498 250001 250001 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_mask_75_list[47]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904dd41",
   "metadata": {},
   "source": [
    "## Write Masked Strings to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "713ca7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./QE Outputs/masked_train_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80cccd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./QE Outputs/masked_dev_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(dev_mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "805b3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./QE Outputs/masked_test20_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test20_mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ceb5c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./QE Outputs/masked_train_60_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_mask_60_list))\n",
    "    \n",
    "with open('./QE Outputs/masked_dev_60_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(dev_mask_60_list))\n",
    "    \n",
    "with open('./QE Outputs/masked_test20_60_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test20_mask_60_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4be0376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./QE Outputs/masked_train_75_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_mask_75_list))\n",
    "    \n",
    "with open('./QE Outputs/masked_dev_75_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(dev_mask_75_list))\n",
    "    \n",
    "with open('./QE Outputs/masked_test20_75_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test20_mask_75_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "402b8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./QE Outputs/masked_train_40_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_mask_40_list))\n",
    "    \n",
    "with open('./QE Outputs/masked_dev_40_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(dev_mask_40_list))\n",
    "    \n",
    "with open('./QE Outputs/masked_test20_40_strings.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test20_mask_40_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc625b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
